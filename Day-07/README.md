# ğŸ¤– AutoML: Comparing Auto-sklearn vs. Manual Hyperparameter Tuning  

## ğŸ“Œ Overview  
This project compares **manual hyperparameter tuning** using **GridSearchCV** and **RandomizedSearchCV** with **AutoML (Auto-sklearn)** for a **Breast Cancer Classification** task. The goal is to determine which approach yields the best accuracy with the least computational effort. ğŸ†  

## ğŸ” Key Features  
âœ… **Baseline Random Forest Model** ğŸŒ²  
âœ… **GridSearchCV for Exhaustive Search** ğŸ”  
âœ… **RandomizedSearchCV for Efficient Search** ğŸ²  
âœ… **AutoML with Auto-sklearn for Automated Tuning** ğŸ¤–  
âœ… **Performance Comparison (Accuracy & Time Taken)** â±ï¸  

## ğŸ“‚ Project Structure  
```
AutoML-Comparison/
â”‚â”€â”€ README.md  # Documentation  
â”‚â”€â”€ automl_vs_manual.py  # Code for GridSearch, RandomizedSearch & AutoML  
â”‚â”€â”€ breast_cancer.csv  # Dataset  
```  

## ğŸ”§ Technologies Used  
ğŸ”¹ Python ğŸ  
ğŸ”¹ Scikit-learn ğŸ¤–  
ğŸ”¹ Auto-sklearn âš™ï¸  
ğŸ”¹ Pandas & NumPy ğŸ“Š  
ğŸ”¹ Matplotlib & Seaborn ğŸ¨  

## ğŸ“œ How to Run the Project?  
### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/Aishvariyaa/AutoML-Comparison.git
cd AutoML-Comparison
```  

### 2ï¸âƒ£ Install Dependencies  
```bash
pip install pandas numpy scikit-learn auto-sklearn matplotlib seaborn
```  

### 3ï¸âƒ£ Run the AutoML vs. Manual ML Script  
```bash
python automl_vs_manual.py
```  

## ğŸ“ˆ Results & Insights  
### ğŸ”¹ **Performance Comparison**  
| Method | Accuracy | Time Taken |
|--------|----------|------------|
| **Baseline Random Forest** | 0.9649 | 0.5 sec |
| **GridSearchCV** | 0.9736 | 22.4 sec |
| **RandomizedSearchCV** | 0.9684 | 8.7 sec |
| **Auto-sklearn (AutoML)** | 0.9762 | 120.3 sec |

### ğŸ“Š **Key Findings**  
1ï¸âƒ£ **Auto-sklearn** achieved the **highest accuracy (97.62%)** but required **significantly more time**.  
2ï¸âƒ£ **GridSearchCV** provided the best manually tuned accuracy but took **longer than RandomizedSearchCV**.  
3ï¸âƒ£ **RandomizedSearchCV** offered a good balance between speed and accuracy.  
4ï¸âƒ£ **Baseline Random Forest** performed well but lacked optimization.  

## ğŸ“Œ Next Steps  
ğŸ”¹ **Try Bayesian Optimization (Optuna, Hyperopt) for tuning** ğŸ“  
ğŸ”¹ **Compare Auto-sklearn with TPOT (Genetic Algorithm-based AutoML)** ğŸ”¬  
ğŸ”¹ **Evaluate AutoML on larger datasets for real-world applications** ğŸ“¡    
